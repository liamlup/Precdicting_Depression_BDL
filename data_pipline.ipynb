{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:54:58.580313Z",
     "start_time": "2023-08-01T11:54:58.564494Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Depression scores from questionnaire of 2005-2018\n",
    "files = [\"DPQ_D.XPT\", \"DPQ_E.XPT\", \"DPQ_F.XPT\", \"DPQ_G.XPT\", \"DPQ_H.XPT\", \"DPQ_I.XPT\", \"DPQ_J.XPT\"]\n",
    "\n",
    "columns = [\"DPQ0\" + str(i) for i in range(10, 100, 10)]  # DPQ010 to DPQ090\n",
    "columns.insert(0,'SEQN')  # add SEQN column\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/questionnaire/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "\n",
    "# combine all dataframes\n",
    "combined_df = pd.concat(dfs)\n",
    "combined_df = combined_df[(combined_df != 7) & (combined_df != 9)].dropna()\n",
    "combined_df = np.round(combined_df, 0).astype('int64')\n",
    "combined_df['score'] = combined_df.sum(axis=1) - combined_df['SEQN']\n",
    "combined_df = combined_df[['SEQN', 'score']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:54:59.821192Z",
     "start_time": "2023-08-01T11:54:59.716107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# complete blood count\n",
    "files = [\"CBC_D.XPT\", \"CBC_E.XPT\", \"CBC_F.XPT\", \"CBC_G.XPT\", \"CBC_H.XPT\", \"CBC_I.XPT\", \"CBC_J.XPT\"]\n",
    "columns = [\"SEQN\",\"LBXWBCSI\",\"LBXLYPCT\",\"LBXMOPCT\", \"LBXNEPCT\", \"LBXEOPCT\", \"LBXBAPCT\", \"LBXRBCSI\", \"LBXHGB\", \"LBXMCVSI\", \"LBXRDW\", \"LBXPLTSI\",\"LBXMPSI\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/CBC/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "CBC_df = pd.concat(dfs)\n",
    "CBC_df = CBC_df.dropna()\n",
    "# convert SEQN to int\n",
    "CBC_df['SEQN'] = CBC_df['SEQN'].astype('int64')\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, CBC_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:00.552725Z",
     "start_time": "2023-08-01T11:55:00.354638Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# demographics\n",
    "files = [\"DEMO_D.XPT\", \"DEMO_E.XPT\", \"DEMO_F.XPT\", \"DEMO_G.XPT\", \"DEMO_H.XPT\", \"DEMO_I.XPT\", \"DEMO_J.XPT\"]\n",
    "columns = [\"SEQN\",\"RIAGENDR\", \"RIDAGEYR\", \"DMDEDUC2\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/demo/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "demo_df = pd.concat(dfs)\n",
    "demo_df = demo_df.dropna()\n",
    "demo_df = demo_df[(demo_df != 7) & (demo_df != 9)].dropna()\n",
    "demo_df = np.round(demo_df, 0).astype('int64')\n",
    "demo_df['male'] = (demo_df['RIAGENDR'] == 1)*1\n",
    "demo_df['female'] = (demo_df['RIAGENDR'] == 2)*1\n",
    "demo_df = demo_df.drop(columns=['RIAGENDR'])\n",
    "demo_df.rename(columns={'RIDAGEYR': 'age', 'DMDEDUC2': 'education'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, demo_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:01.450121Z",
     "start_time": "2023-08-01T11:55:00.955912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# sleep 2005-2014\n",
    "files = [\"SLQ_D.XPT\", \"SLQ_E.XPT\", \"SLQ_F.XPT\", \"SLQ_G.XPT\", \"SLQ_H.XPT\"]\n",
    "columns = ['SEQN', 'SLD010H']\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/sleep/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "# 2015-2016\n",
    "df = pd.read_sas('data/sleep/' + 'SLQ_I.XPT',format='xport',encoding='utf-8')  # read the file\n",
    "df = df[[\"SEQN\", 'SLD012']] # extract the required columns\n",
    "df.rename(columns={'SLD012': 'SLD010H'}, inplace=True)\n",
    "dfs.append(df)\n",
    "\n",
    "df = pd.read_sas('data/sleep/' + 'SLQ_J.XPT',format='xport',encoding='utf-8')  # read the file\n",
    "df = df[[\"SEQN\", 'SLD012']] # extract the required columns\n",
    "df.rename(columns={'SLD012': 'SLD010H'}, inplace=True)\n",
    "dfs.append(df)\n",
    "\n",
    "sleep_df = pd.concat(dfs)\n",
    "sleep_df = sleep_df[(sleep_df != 77) & (sleep_df != 99)].dropna()\n",
    "sleep_df = np.round(sleep_df, 0).astype('int64')\n",
    "sleep_df.rename(columns={'SLD010H': 'sleep'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, sleep_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:01.973335Z",
     "start_time": "2023-08-01T11:55:01.853068Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# alcohol\n",
    "files = [\"ALQ_D.XPT\", \"ALQ_E.XPT\", \"ALQ_F.XPT\", \"ALQ_G.XPT\", \"ALQ_H.XPT\", \"ALQ_I.XPT\", \"ALQ_J.XPT\"]\n",
    "columns = ['SEQN', 'ALQ130']\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/alcohol/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "\n",
    "alcohol_df = pd.concat(dfs)\n",
    "alcohol_df = alcohol_df[(alcohol_df != 777) & (alcohol_df != 999)].dropna()\n",
    "alcohol_df = np.round(alcohol_df, 0).astype('int64')\n",
    "alcohol_df.rename(columns={'ALQ130': 'alcohol'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, alcohol_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:02.468026Z",
     "start_time": "2023-08-01T11:55:02.334519Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# diet\n",
    "files = [\"DBQ_D.XPT\", \"DBQ_E.XPT\", \"DBQ_F.XPT\", \"DBQ_G.XPT\", \"DBQ_H.XPT\", \"DBQ_I.XPT\", \"DBQ_J.XPT\"]\n",
    "columns = [\"SEQN\", \"DBQ700\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/diet/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "    \n",
    "diet_df = pd.concat(dfs)\n",
    "diet_df = diet_df[(diet_df != 7) & (diet_df != 9)].dropna()\n",
    "diet_df = np.round(diet_df, 0).astype('int64')\n",
    "# how healthy is diet: 5 is best, 1 is worst\n",
    "diet_df['DBQ700'] = 6 - diet_df['DBQ700']\n",
    "diet_df.rename(columns={'DBQ700': 'diet'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, diet_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:03.230404Z",
     "start_time": "2023-08-01T11:55:02.711543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# physical activity\n",
    "files = [\"PAQ_E.XPT\", \"PAQ_F.XPT\", \"PAQ_G.XPT\", \"PAQ_H.XPT\", \"PAQ_I.XPT\", \"PAQ_J.XPT\"]\n",
    "columns = [\"SEQN\",\"PAQ650\", \"PAQ665\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/physical_activity/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "# 2005-2006\n",
    "df = pd.read_sas('data/physical_activity/' + 'PAQ_D.XPT',format='xport',encoding='utf-8')  # read the file\n",
    "df = df[[\"SEQN\",\"PAD200\", \"PAD320\"]] # extract the required columns\n",
    "# change the value 3 to 2\n",
    "df['PAD200'] = df['PAD200'].replace(3, 2)\n",
    "df['PAD320'] = df['PAD320'].replace(3, 2)\n",
    "df.rename(columns={'PAD200': 'PAQ650', 'PAD320': 'PAQ665'}, inplace=True)\n",
    "dfs.append(df)\n",
    "\n",
    "    \n",
    "physical_activity_df = pd.concat(dfs)\n",
    "physical_activity_df = physical_activity_df[(physical_activity_df != 7) & (physical_activity_df != 9)].dropna()\n",
    "physical_activity_df = np.round(physical_activity_df, 0).astype('int64')\n",
    "physical_activity_df.replace(2, 0, inplace=True)\n",
    "physical_activity_df.rename(columns={'PAQ650': 'vigorous activity', 'PAQ665': 'moderate activity'}, inplace=True)\n",
    "# sort by SEQN in ascending order\n",
    "physical_activity_df.sort_values(by=['SEQN'], inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, physical_activity_df, on='SEQN')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:03.615940Z",
     "start_time": "2023-08-01T11:55:03.236524Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# smoking\n",
    "files = [\"SMQ_D.XPT\",\"SMQ_E.XPT\", \"SMQ_F.XPT\", \"SMQ_G.XPT\", \"SMQ_H.XPT\", \"SMQ_I.XPT\", \"SMQ_J.XPT\"]\n",
    "columns = [\"SEQN\", \"SMQ040\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/smoking/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "\n",
    "smoking_df = pd.concat(dfs)\n",
    "smoking_df = smoking_df[(smoking_df != 7) & (smoking_df != 9)].dropna()\n",
    "smoking_df = np.round(smoking_df, 0).astype('int64')\n",
    "smoking_df.rename(columns={'SMQ040': 'smoking'}, inplace=True)\n",
    "# change  3 to 0, 2 to 1, and 1 to 2\n",
    "smoking_df['smoking'] = smoking_df['smoking'].replace(3, 0)\n",
    "smoking_df['smoking'] = smoking_df['smoking'].replace(2, 3)\n",
    "smoking_df['smoking'] = smoking_df['smoking'].replace(1, 2) #temp\n",
    "smoking_df['smoking'] = smoking_df['smoking'].replace(3, 1)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, smoking_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:03.911231Z",
     "start_time": "2023-08-01T11:55:03.624655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Blood pressure\n",
    "files = [\"BPX_D.XPT\", \"BPX_E.XPT\", \"BPX_F.XPT\", \"BPX_G.XPT\", \"BPX_H.XPT\", \"BPX_I.XPT\", \"BPX_J.XPT\"]\n",
    "columns = [\"SEQN\", \"BPXSY1\", \"BPXDI1\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/BP/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "    \n",
    "blood_pressure_df = pd.concat(dfs)\n",
    "blood_pressure_df = blood_pressure_df.dropna()\n",
    "blood_pressure_df = np.round(blood_pressure_df, 0).astype('int64')\n",
    "blood_pressure_df.rename(columns={'BPXSY1': 'SBP', 'BPXDI1': 'DBP'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, blood_pressure_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:04.244927Z",
     "start_time": "2023-08-01T11:55:04.033597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# weight [kG]\n",
    "files = [\"BMX_D.XPT\", \"BMX_E.XPT\", \"BMX_F.XPT\", \"BMX_G.XPT\", \"BMX_H.XPT\", \"BMX_I.XPT\", \"BMX_J.XPT\"]\n",
    "columns = [\"SEQN\", \"BMXWT\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/weight/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "    \n",
    "weight_df = pd.concat(dfs)\n",
    "weight_df = weight_df.dropna()\n",
    "\n",
    "weight_df.rename(columns={'BMXWT': 'weight'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, weight_df, on='SEQN')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:04.729787Z",
     "start_time": "2023-08-01T11:55:04.536637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# diabetes\n",
    "files = [\"DIQ_D.XPT\", \"DIQ_E.XPT\", \"DIQ_F.XPT\", \"DIQ_G.XPT\", \"DIQ_H.XPT\", \"DIQ_I.XPT\", \"DIQ_J.XPT\"]\n",
    "columns = [\"SEQN\", \"DIQ010\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/diabetes/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "    \n",
    "diabetes_df = pd.concat(dfs)\n",
    "diabetes_df = diabetes_df.dropna()\n",
    "diabetes_df = np.round(diabetes_df, 0).astype('int64')\n",
    "diabetes_df = diabetes_df[(diabetes_df != 7) & (diabetes_df != 9)].dropna()\n",
    "diabetes_df.rename(columns={'DIQ010': 'diabetes'}, inplace=True)\n",
    "# replace 1 with 2, 2 with 0 and 3 with 1\n",
    "diabetes_df['diabetes'] = diabetes_df['diabetes'].replace({1: 2, 2: 0, 3: 1})\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, diabetes_df, on='SEQN')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:05.379268Z",
     "start_time": "2023-08-01T11:55:04.965306Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# cholesterol [mg/dL]\n",
    "files = ['HDL_D.XPT', 'HDL_E.XPT', 'HDL_F.XPT', 'HDL_G.XPT', 'HDL_H.XPT', 'HDL_I.XPT', 'HDL_J.XPT']\n",
    "columns = [\"SEQN\", \"LBDHDD\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/cholesterol_HDL/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "\n",
    "cholesterol_df = pd.concat(dfs)\n",
    "cholesterol_df = cholesterol_df.dropna().astype('int64')\n",
    "cholesterol_df.rename(columns={'LBDHDD': 'cholesterol_HDL'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, cholesterol_df, on='SEQN')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:05.565294Z",
     "start_time": "2023-08-01T11:55:05.510050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# cholesterol LDL and triglycerides [mg/dL]\n",
    "files = ['TRIGLY_D.XPT', 'TRIGLY_E.XPT', 'TRIGLY_F.XPT', 'TRIGLY_G.XPT', 'TRIGLY_H.XPT', 'TRIGLY_I.XPT', 'TRIGLY_J.XPT']\n",
    "columns = [\"SEQN\", \"LBXTR\", \"LBDLDL\"]\n",
    "dfs = []  # list to store dataframes\n",
    "\n",
    "for file in  files:\n",
    "    df = pd.read_sas('data/cholesterol_LDL/' + file,format='xport',encoding='utf-8')  # read the file\n",
    "    df = df[columns] # extract the required columns\n",
    "    dfs.append(df)\n",
    "    \n",
    "cholesterol_LDL_triglycerides_df = pd.concat(dfs)\n",
    "cholesterol_LDL_triglycerides_df = cholesterol_LDL_triglycerides_df.dropna().astype('int64')\n",
    "cholesterol_LDL_triglycerides_df.rename(columns={'LBXTR': 'triglycerides', 'LBDLDL': 'cholesterol_LDL'}, inplace=True)\n",
    "# merge with combined_df\n",
    "combined_df = pd.merge(combined_df, cholesterol_LDL_triglycerides_df, on='SEQN')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:06.072933Z",
     "start_time": "2023-08-01T11:55:06.006442Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# create depression column with 1 if score is equal or greater than 10 and 0 otherwise\n",
    "combined_df['depression'] = np.where(combined_df['score'] >= 10, 1, 0)\n",
    "# drop score\n",
    "combined_df.drop(columns=['SEQN','score'], inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:08.983976Z",
     "start_time": "2023-08-01T11:55:08.977204Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# save to csv\n",
    "combined_df.to_csv('data/combined.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T11:55:36.557100Z",
     "start_time": "2023-08-01T11:55:36.493202Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
